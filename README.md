# llm-guard
A fast, explainable **Rust** CLI that scans prompts/logs for **prompt-injection &amp; jailbreak indicators**, scores the risk (0â€“100), and optionally asks an LLM (e.g., Codex) for a short verdict and mitigation tip.
